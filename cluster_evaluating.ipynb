{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.numeric import NaN\n",
    "import pylab\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows the prediction of clusters for rows with missing values.\n",
    "600 of 2000 rows contain missing values up to 5 dimensions. (70% safe rows / 30% unsafe rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_VALUE = 1000000\n",
    "CLUSTER_NUMBER = 4\n",
    "GAMMA = 10\n",
    "\n",
    "# preprocess data\n",
    "with open('wifi_localization.txt') as f:\n",
    "    file = f.readlines()\n",
    "data = []\n",
    "for row in file:\n",
    "    data.append(([int(item) for item in row.split(\"\\t\")[:-1]],\n",
    "                 int(row.split(\"\\t\")[-1].split(\"\\n\")[0])-1))\n",
    "random.shuffle(data)\n",
    "points = np.array([item[0] for item in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_specific_values_in_one_dimension(points, column, number_of_deleted_values):\n",
    "    for i in range(number_of_deleted_values):\n",
    "        position_of_array_deleted_in_array = random.randint(0, len(points) - 1)\n",
    "        position_of_value_deleted_in_array = column\n",
    "        points[position_of_array_deleted_in_array][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "\n",
    "def delete_values_in_data(points, number_of_deleted_values):\n",
    "    for i in range(number_of_deleted_values):\n",
    "        position_of_array_deleted_in_array = random.randint(0, len(points) - 1)\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[position_of_array_deleted_in_array]) - 1)\n",
    "        points[position_of_array_deleted_in_array][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "def delete_random_values_in_data(points):\n",
    "    for i in range(len(points)):\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "## this function can be configured to change the number of delete dimensions (standard is deleting up to five dimensions)\n",
    "def delete_up_to_five_dimensions_in_data(points):\n",
    "    for i in range(len(points)):\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data rows with incomplete data from the hole dataset\n",
    "# data: numpy.array\n",
    "# returns a numpy.array only with complete data rows\n",
    "def split_data_in_completes(data):\n",
    "    # select only rows with complete data and save it in completes\n",
    "    completes = np.array(data)\n",
    "    row = 0\n",
    "    while row < len(completes):\n",
    "        column = 0\n",
    "        while column < len(completes[row]):\n",
    "            if completes[row][column] == MISSING_VALUE:\n",
    "                completes = np.delete(\n",
    "                    completes, row, 0)\n",
    "                row -= 1\n",
    "            column += 1\n",
    "        row += 1\n",
    "    return completes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data rows with complete data from the hole dataset\n",
    "# data: numpy.array\n",
    "# returns a numpy.array only with incomplete data rows\n",
    "def split_data_in_incompletes(data):\n",
    "    incompletes = np.array(data)\n",
    "    row = 0\n",
    "    while row < len(incompletes):\n",
    "        column = 0\n",
    "        delete = True\n",
    "        # Search for missing value\n",
    "        while column < len(incompletes[row]):\n",
    "            if incompletes[row][column] == MISSING_VALUE:\n",
    "                delete = False\n",
    "            column += 1\n",
    "        # If there was a missing value found, delete the row\n",
    "        if delete:\n",
    "            incompletes = np.delete(\n",
    "                incompletes, row, 0)\n",
    "            row -= 1\n",
    "        row += 1\n",
    "    return incompletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the means subspace of safe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a numpy.array with the length of the safe dimensions and their means from the gmm\n",
    "def calculate_subspace_means_safe_dimensions(row, gmm_means):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_means_safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the covariances subspace of safe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all covariances of the gmm\n",
    "# returns a numpy.array with the length of the safe dimensions and their covariances from the gmm\n",
    "def calculate_subspace_covariances_safe_dimensions(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_covariances_safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the means subspace of unsafe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a numpy.array with the length of the unsafe dimensions and their means from the gmm\n",
    "def calculate_subspace_means_unsafe_dimensions(row, gmm_means):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neuer Erwartungswert\n",
    "        subspace_means_unsafe_dimensions = np.delete(gmm_means[cluster], index_safe_dimensions,axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_means_unsafe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the covariances subspace of unsafe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all covariances of the gmm\n",
    "# returns a numpy.array with the length of the unsafe dimensions and their covariances from the gmm\n",
    "def calculate_subspace_covariances_unsafe_dimensions(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neue Kovarianzmatrix\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_safe_dimensions, axis=1)\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(subspace_covariances_unsafe_dimensions, index_safe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_covariances_unsafe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the new means for the new gmm (new_means is a list of all subspace_means_unsafe_dimensions)\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a list of numpy.arrays with the length of the safe dimensions and their means from the gmm\n",
    "def calculate_new_means(row, gmm_means):\n",
    "    cluster = 0\n",
    "    new_means = np.zeros((1,np.count_nonzero(row == MISSING_VALUE)))\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # new mean\n",
    "        subspace_means_unsafe_dimensions = np.delete(gmm_means[cluster], index_safe_dimensions,axis=0)\n",
    "        new_means = np.append(new_means, [subspace_means_unsafe_dimensions], axis=0)\n",
    "        cluster += 1\n",
    "    new_means = np.delete(new_means,0, axis=0)\n",
    "    return new_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the new covariances for the new gmm (new_covariances is a list of all subspace_covariances_unsafe_dimensions)\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all means of the gmm\n",
    "# returns a list of numpy.arrays with the length of the safe dimensions and their covariances from the gmm\n",
    "def calculate_new_covariances(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    new_covariances = np.zeros((1,np.count_nonzero(row == MISSING_VALUE),np.count_nonzero(row == MISSING_VALUE)))\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # new covariances\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_safe_dimensions, axis=1)\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(subspace_covariances_unsafe_dimensions, index_safe_dimensions, axis=0)\n",
    "        new_covariances = np.append(new_covariances, [subspace_covariances_unsafe_dimensions], axis=0)\n",
    "        cluster += 1\n",
    "    new_covariances = np.delete(new_covariances,0, axis=0)\n",
    "    return new_covariances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values of the safe dimensions\n",
    "# row: one row in a numpy.array\n",
    "# returns numpy.array with all safe dimensions\n",
    "def get_safe_dimensions(row):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "        cluster += 1\n",
    "    return safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c of a row with gamma\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: means of the gmm\n",
    "# covariances: covariances of the gmm\n",
    "# returns a list of all c's (for example if the gmm contains five clusters the array contains five values) \n",
    "def calculate_c_with_gamma(row, gmm_means, gmm_covariances):\n",
    "    cluster = 0\n",
    "    c_list_gamma = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "        gamma_matrix = np.zeros((len(safe_dimensions),len(safe_dimensions)))\n",
    "        i = 0\n",
    "        while i < len(safe_dimensions):\n",
    "            gamma_matrix[i][i] = GAMMA\n",
    "            i+= 1\n",
    "        subspace_covariances_safe_dimensions_with_gamma = gamma_matrix + subspace_covariances_safe_dimensions\n",
    "        c_i_gamma = multivariate_normal.pdf(safe_dimensions, mean=subspace_means_safe_dimensions, cov=subspace_covariances_safe_dimensions_with_gamma)\n",
    "        c_list_gamma = np.append(c_list_gamma,c_i_gamma)\n",
    "        cluster += 1\n",
    "    c_list_gamma = c_list_gamma[CLUSTER_NUMBER:]\n",
    "    return c_list_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c of a row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: means of the gmm\n",
    "# covariances: covariances of the gmm\n",
    "# returns a list of all c's (for example if the gmm contains five clusters the array contains five values) \n",
    "def calculate_c(row, gmm_means, gmm_covariances):\n",
    "    cluster = 0\n",
    "    c_list = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "    \n",
    "        c_i = multivariate_normal.pdf(safe_dimensions, mean=subspace_means_safe_dimensions, cov=subspace_covariances_safe_dimensions)\n",
    "        c_list = np.append(c_list,c_i)\n",
    "        cluster += 1\n",
    "    c_list = c_list[CLUSTER_NUMBER:]\n",
    "    \n",
    "    return c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the new weights for the gmm (r in the paper)\n",
    "# c_list_gamma: is a list with all c's (c in the paper)\n",
    "# gmm_weights: weights of the gmm\n",
    "# returns new weights for the gmm as numpy.array\n",
    "def calculate_new_weights_gamma(c_list_gamma, gmm_weights):\n",
    "    multiplicated_list = [c_list_gamma*gmm_weights for c_list_gamma,gmm_weights in zip(c_list_gamma,gmm_weights)]\n",
    "    sum_multiplicated_list = sum(multiplicated_list)\n",
    "\n",
    "    # normalize known dimensions\n",
    "    cluster = 0\n",
    "    new_weights_gamma = np.zeros([CLUSTER_NUMBER])\n",
    "\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        r_i = ((c_list_gamma[cluster]*gmm_weights[cluster]) / sum_multiplicated_list)\n",
    "        new_weights_gamma = np.append(new_weights_gamma,r_i)\n",
    "        cluster += 1\n",
    "    # new weights\n",
    "    new_weights_gamma = new_weights_gamma[CLUSTER_NUMBER:]\n",
    "    return new_weights_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the new weights for the gmm (r in the paper)\n",
    "# c_list: is a list with all c's (c in the paper)\n",
    "# gmm_weights: weights of the gmm\n",
    "# returns new weights for the gmm as numpy.array\n",
    "def calculate_new_weights(c_list, gmm_weights):\n",
    "    multiplicated_list = [c_list*gmm_weights for c_list,gmm_weights in zip(c_list,gmm_weights)]\n",
    "    sum_multiplicated_list = sum(multiplicated_list)\n",
    "\n",
    "    # normalize known dimensions\n",
    "    cluster = 0\n",
    "    new_weights = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        r_i = ((c_list[cluster]*gmm_weights[cluster]) / sum_multiplicated_list)\n",
    "        new_weights = np.append(new_weights,r_i)\n",
    "        cluster += 1\n",
    "    # new weights\n",
    "    new_weights = new_weights[CLUSTER_NUMBER:]\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "# points: numpy.array with missing_values\n",
    "# returns a list of tupels which has the length of all incomplete data rows (when points has 25 rows with missing values the list of the tupels has the length of 25)\n",
    "# one tupel contains the new weights, new covariances and new means for the missing dimensions\n",
    "def gmm_distribution_missing_values(points):\n",
    "    means_covariances_weights_list = []\n",
    "    means_covariances_weights_list_gamma = []\n",
    "    new_weights_list = []\n",
    "    new_weights_gamma_list = []\n",
    "    # delete random values \n",
    "    \n",
    "    # delete a certain number of values\n",
    "    #points = delete_values_in_data(points, 100)\n",
    "\n",
    "    # delete values in one dimension\n",
    "    #points = delete_specific_values_in_one_dimension(points, 3, 20)\n",
    "\n",
    "    completes = split_data_in_completes(points)\n",
    "\n",
    "    gmm = GaussianMixture(covariance_type=\"diag\", n_components=CLUSTER_NUMBER, random_state = 3).fit(\n",
    "        completes[:1399])\n",
    "    gmm_means = np.array(gmm.means_)\n",
    "    gmm_covariances = np.array(gmm.covariances_)\n",
    "    gmm_weights = np.array(gmm.weights_)\n",
    "    \n",
    "    # initial gmm predicts the clusters with complete values\n",
    "    pred_cluster = gmm.predict(points[1400:])\n",
    "    # delete values in 600 rows\n",
    "    points_incompletes = delete_up_to_five_dimensions_in_data(points[1400:])\n",
    "    print(\"Datensatz, der gelöschte Werte beinhaltet: \",points_incompletes)\n",
    "\n",
    "    incompletes = split_data_in_incompletes(points)\n",
    "\n",
    "    for row in points_incompletes:\n",
    "        subspace_means_safe_dimensions = calculate_subspace_means_safe_dimensions(row, gmm_means)\n",
    "        subspace_covariances_safe_dimensions = calculate_subspace_covariances_safe_dimensions(row, gmm_covariances)\n",
    "        subspace_means_unsafe_dimensions = calculate_subspace_means_unsafe_dimensions(row, gmm_means)\n",
    "        subspace_covariances_unsafe_dimensions = calculate_subspace_covariances_unsafe_dimensions(row, gmm_covariances)\n",
    "        new_means = calculate_new_means(row, gmm_means)\n",
    "        new_covariances = calculate_new_covariances(row, gmm_covariances)\n",
    "        safe_dimensions = get_safe_dimensions(row)\n",
    "        c_list_gamma = calculate_c_with_gamma(row, gmm_means, gmm_covariances)\n",
    "        c_list = calculate_c(row, gmm_means, gmm_covariances)\n",
    "        new_weights_gamma = calculate_new_weights_gamma(c_list_gamma,gmm_weights)\n",
    "        new_weights = calculate_new_weights(c_list,gmm_weights)\n",
    "        new_weights_list.append(new_weights)\n",
    "        new_weights_gamma_list.append(new_weights_gamma)\n",
    "\n",
    "    return new_weights_list, pred_cluster, new_weights_gamma_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented method predicts the clusters of the missing rows\n",
    "def pred_cluster_new_gmm(new_weights, pred_cluster):\n",
    "    new_list = []\n",
    "    pred_cluster_list = []\n",
    "    i = 0\n",
    "    while i < 600:\n",
    "        max_index = new_weights[i].argmax(axis=0)\n",
    "        pred_cluster_list.append(max_index)\n",
    "        i += 1\n",
    "\n",
    "    new_list = [pred_cluster_list_i - pred_cluster_i for pred_cluster_list_i, pred_cluster_i in zip(pred_cluster_list, pred_cluster)]\n",
    "    percent_of_precited = round(new_list.count(0) / len(new_list) * 100,2)\n",
    "    print(\"Clusterzuordnung ohne Gamma\")\n",
    "    print(\"Von \",len(new_list), \" Reihen, die unvollständig sind, wurden \",new_list.count(0), \" in das richtige Cluster zugeordnet. Das entspricht \",percent_of_precited, \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implemented method predicts the clusters of the missing rows with gamma\n",
    "def pred_cluster_new_gmm_gamma(new_weights_gamma, pred_cluster):\n",
    "    new_list = []\n",
    "    pred_cluster_list = []\n",
    "    \n",
    "    i = 0\n",
    "    while i < 600:\n",
    "        max_index = new_weights_gamma[i].argmax(axis=0)\n",
    "        pred_cluster_list.append(max_index)\n",
    "        i += 1\n",
    "\n",
    "    new_list = [pred_cluster_list_i - pred_cluster_i for pred_cluster_list_i, pred_cluster_i in zip(pred_cluster_list, pred_cluster)]\n",
    "    percent_of_precited = round(new_list.count(0) / len(new_list) * 100,2)\n",
    "    print(\"Clusterzuordnung mit Gamma\")\n",
    "    print(\"Von \",len(new_list), \" Reihen, die unvollständig sind, wurden \",new_list.count(0), \" in das richtige Cluster zugeordnet. Das entspricht \",percent_of_precited, \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datensatz, der gelöschte Werte beinhaltet:  [[1000000 1000000     -65 ...     -77     -89     -90]\n",
      " [    -42 1000000 1000000 ... 1000000     -77     -73]\n",
      " [1000000 1000000 1000000 ...     -65     -79 1000000]\n",
      " ...\n",
      " [1000000 1000000     -65 ...     -68     -80     -83]\n",
      " [    -69     -58 1000000 ...     -73     -81 1000000]\n",
      " [1000000 1000000 1000000 ...     -43     -89 1000000]]\n",
      "Clusterzuordnung ohne Gamma\n",
      "Von  600  Reihen, die unvollständig sind, wurden  519  in das richtige Cluster zugeordnet. Das entspricht  86.5 %.\n",
      "Clusterzuordnung mit Gamma\n",
      "Von  600  Reihen, die unvollständig sind, wurden  515  in das richtige Cluster zugeordnet. Das entspricht  85.83 %.\n"
     ]
    }
   ],
   "source": [
    "new_weights, pred_cluster, new_weights_gamma = gmm_distribution_missing_values(points)\n",
    "pred_cluster_new_gmm(new_weights, pred_cluster)\n",
    "pred_cluster_new_gmm_gamma(new_weights_gamma, pred_cluster)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e6e376889b46e5d2afa5f6d19b0811f4e7fea2a291bc45d33c4bc190b0b6db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
