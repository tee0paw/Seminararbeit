{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.core.numeric import NaN\n",
    "import pylab\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_VALUE = 1000000\n",
    "CLUSTER_NUMBER = 15\n",
    "GAMMA = 10\n",
    "\n",
    "# preprocess data\n",
    "with open('wifi_localization.txt') as f:\n",
    "    file = f.readlines()\n",
    "data = []\n",
    "for row in file:\n",
    "    data.append(([int(item) for item in row.split(\"\\t\")[:-1]],\n",
    "                 int(row.split(\"\\t\")[-1].split(\"\\n\")[0])-1))\n",
    "#random.shuffle(data)\n",
    "points = np.array([item[0] for item in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for testing\n",
    "#points[0][0] = MISSING_VALUE\n",
    "#points[0][2] = MISSING_VALUE\n",
    "#points[0][5] = MISSING_VALUE\n",
    "#points[0][6] = MISSING_VALUE\n",
    "#points[0][3] = MISSING_VALUE\n",
    "#points[0][4] = MISSING_VALUE\n",
    "#points[0][1] = MISSING_VALUE\n",
    "#points[3][2] = MISSING_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_specific_values_in_one_dimension(points, column, number_of_deleted_values):\n",
    "    for i in range(number_of_deleted_values):\n",
    "        position_of_array_deleted_in_array = random.randint(0, len(points) - 1)\n",
    "        position_of_value_deleted_in_array = column\n",
    "        points[position_of_array_deleted_in_array][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "\n",
    "def delete_values_in_data(points, number_of_deleted_values):\n",
    "    for i in range(number_of_deleted_values):\n",
    "        position_of_array_deleted_in_array = random.randint(0, len(points) - 1)\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[position_of_array_deleted_in_array]) - 1)\n",
    "        points[position_of_array_deleted_in_array][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "def delete_random_values_in_data(points):\n",
    "    for i in range(len(points)):\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points\n",
    "\n",
    "def delete_two_random_values_in_data(points):\n",
    "    for i in range(len(points)):\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "\n",
    "        position_of_value_deleted_in_array = random.randint(\n",
    "        0, len(points[i]) - 1)\n",
    "        points[i][position_of_value_deleted_in_array] = MISSING_VALUE\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data rows with incomplete data from the hole dataset\n",
    "# data: numpy.array\n",
    "# returns a numpy.array only with complete data rows\n",
    "def split_data_in_completes(data):\n",
    "    # select only rows with complete data and save it in completes\n",
    "    completes = np.array(data)\n",
    "    row = 0\n",
    "    while row < len(completes):\n",
    "        column = 0\n",
    "        while column < len(completes[row]):\n",
    "            if completes[row][column] == MISSING_VALUE:\n",
    "                completes = np.delete(\n",
    "                    completes, row, 0)\n",
    "                row -= 1\n",
    "            column += 1\n",
    "        row += 1\n",
    "    return completes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all data rows with complete data from the hole dataset\n",
    "# data: numpy.array\n",
    "# returns a numpy.array only with incomplete data rows\n",
    "def split_data_in_incompletes(data):\n",
    "    incompletes = np.array(data)\n",
    "    row = 0\n",
    "    while row < len(incompletes):\n",
    "        column = 0\n",
    "        delete = True\n",
    "        # Search for missing value\n",
    "        while column < len(incompletes[row]):\n",
    "            if incompletes[row][column] == MISSING_VALUE:\n",
    "                delete = False\n",
    "            column += 1\n",
    "        # If there was a missing value found, delete the row\n",
    "        if delete:\n",
    "            incompletes = np.delete(\n",
    "                incompletes, row, 0)\n",
    "            row -= 1\n",
    "        row += 1\n",
    "    return incompletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the means subspace of safe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a numpy.array with the length of the safe dimensions and their means from the gmm\n",
    "def calculate_subspace_means_safe_dimensions(row, gmm_means):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_means_safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the covariances subspace of safe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all covariances of the gmm\n",
    "# returns a numpy.array with the length of the safe dimensions and their covariances from the gmm\n",
    "def calculate_subspace_covariances_safe_dimensions(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_covariances_safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the means subspace of unsafe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a numpy.array with the length of the unsafe dimensions and their means from the gmm\n",
    "def calculate_subspace_means_unsafe_dimensions(row, gmm_means):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neuer Erwartungswert\n",
    "        subspace_means_unsafe_dimensions = np.delete(gmm_means[cluster], index_safe_dimensions,axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_means_unsafe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the covariances subspace of unsafe dimensions in a incomplete data row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all covariances of the gmm\n",
    "# returns a numpy.array with the length of the unsafe dimensions and their covariances from the gmm\n",
    "def calculate_subspace_covariances_unsafe_dimensions(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neue Kovarianzmatrix\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_safe_dimensions, axis=1)\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(subspace_covariances_unsafe_dimensions, index_safe_dimensions, axis=0)\n",
    "        cluster += 1\n",
    "    return subspace_covariances_unsafe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the new means for the new gmm (new_means is a list of all subspace_means_unsafe_dimensions)\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: all means of the gmm\n",
    "# returns a list of numpy.arrays with the length of the safe dimensions and their means from the gmm\n",
    "def calculate_new_means(row, gmm_means):\n",
    "    cluster = 0\n",
    "    new_means = np.zeros((1,np.count_nonzero(row == MISSING_VALUE)))\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neuer Erwartungswert\n",
    "        subspace_means_unsafe_dimensions = np.delete(gmm_means[cluster], index_safe_dimensions,axis=0)\n",
    "        new_means = np.append(new_means, [subspace_means_unsafe_dimensions], axis=0)\n",
    "        cluster += 1\n",
    "    new_means = np.delete(new_means,0, axis=0)\n",
    "    return new_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the new covariances for the new gmm (new_covariances is a list of all subspace_covariances_unsafe_dimensions)\n",
    "# row: one row in a numpy.array\n",
    "# gmm_covariances: all means of the gmm\n",
    "# returns a list of numpy.arrays with the length of the safe dimensions and their covariances from the gmm\n",
    "def calculate_new_covariances(row, gmm_covariances):\n",
    "    cluster = 0\n",
    "    new_covariances = np.zeros((1,np.count_nonzero(row == MISSING_VALUE),np.count_nonzero(row == MISSING_VALUE)))\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        # neue Kovarianzmatrix\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_safe_dimensions, axis=1)\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(subspace_covariances_unsafe_dimensions, index_safe_dimensions, axis=0)\n",
    "        new_covariances = np.append(new_covariances, [subspace_covariances_unsafe_dimensions], axis=0)\n",
    "        cluster += 1\n",
    "    new_covariances = np.delete(new_covariances,0, axis=0)\n",
    "    return new_covariances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the values of the safe dimensions\n",
    "# row: one row in a numpy.array\n",
    "# returns numpy.array with all safe dimensions\n",
    "def get_safe_dimensions(row):\n",
    "    cluster = 0\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "        cluster += 1\n",
    "    return safe_dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c of a row with gamma\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: means of the gmm\n",
    "# covariances: covariances of the gmm\n",
    "# returns a list of all c's (for example if the gmm contains five clusters the array contains five values) \n",
    "def calculate_c_with_gamma(row, gmm_means, gmm_covariances):\n",
    "    cluster = 0\n",
    "    c_list_gamma = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "        gamma_matrix = np.zeros((len(safe_dimensions),len(safe_dimensions)))\n",
    "        i = 0\n",
    "        while i < len(safe_dimensions):\n",
    "            gamma_matrix[i][i] = GAMMA\n",
    "            i+= 1\n",
    "        subspace_covariances_safe_dimensions_with_gamma = gamma_matrix + subspace_covariances_safe_dimensions\n",
    "        #print(subspace_covariances_safe_dimensions)\n",
    "        #print(gamma_matrix)\n",
    "        #print(subspace_covariances_safe_dimensions_with_gamma)\n",
    "        c_i_gamma = multivariate_normal.pdf(safe_dimensions, mean=subspace_means_safe_dimensions, cov=subspace_covariances_safe_dimensions_with_gamma)\n",
    "        c_list_gamma = np.append(c_list_gamma,c_i_gamma)\n",
    "        cluster += 1\n",
    "    c_list_gamma = c_list_gamma[c_list_gamma != 0]\n",
    "    return c_list_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate c of a row\n",
    "# row: one row in a numpy.array\n",
    "# gmm_means: means of the gmm\n",
    "# covariances: covariances of the gmm\n",
    "# returns a list of all c's (for example if the gmm contains five clusters the array contains five values) \n",
    "def calculate_c(row, gmm_means, gmm_covariances):\n",
    "    cluster = 0\n",
    "    c_list = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        safe_dimensions = [value for value in row if MISSING_VALUE != value]\n",
    "        safe_dimensions = np.array(safe_dimensions)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_means_safe_dimensions = np.delete(gmm_means[cluster],index_unsafe_dimensions, axis=0)\n",
    "\n",
    "        index_unsafe_dimensions = [index for index in range(len(row)) if MISSING_VALUE == row[index]]\n",
    "        subspace_covariances_safe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_unsafe_dimensions, axis=1)\n",
    "        subspace_covariances_safe_dimensions = np.delete(subspace_covariances_safe_dimensions, index_unsafe_dimensions, axis=0)\n",
    "    \n",
    "        c_i = multivariate_normal.pdf(safe_dimensions, mean=subspace_means_safe_dimensions, cov=subspace_covariances_safe_dimensions)\n",
    "        c_list = np.append(c_list,c_i)\n",
    "        cluster += 1\n",
    "    c_list = c_list[c_list != 0]\n",
    "    return c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the new weights for the gmm (r in the paper)\n",
    "# c_list_gamma: is a list with all c's (c in the paper)\n",
    "# gmm_weights: weights of the gmm\n",
    "# returns new weights for the gmm as numpy.array\n",
    "def calculate_new_weights_gamma(c_list_gamma, gmm_weights):\n",
    "    multiplicated_list = [c_list_gamma*gmm_weights for c_list_gamma,gmm_weights in zip(c_list_gamma,gmm_weights)]\n",
    "    sum_multiplicated_list = sum(multiplicated_list)\n",
    "\n",
    "    # normalize known dimensions\n",
    "    cluster = 0\n",
    "    new_weights_gamma = np.zeros([CLUSTER_NUMBER])\n",
    "\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        r_i = ((c_list_gamma[cluster]*gmm_weights[cluster]) / sum_multiplicated_list)\n",
    "        new_weights_gamma = np.append(new_weights_gamma,r_i)\n",
    "        cluster += 1\n",
    "    # neue Gewichte\n",
    "    new_weights_gamma = new_weights_gamma[new_weights_gamma != 0]\n",
    "    return new_weights_gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the new weights for the gmm (r in the paper)\n",
    "# c_list: is a list with all c's (c in the paper)\n",
    "# gmm_weights: weights of the gmm\n",
    "# returns new weights for the gmm as numpy.array\n",
    "def calculate_new_weights(c_list, gmm_weights):\n",
    "    multiplicated_list = [c_list*gmm_weights for c_list,gmm_weights in zip(c_list,gmm_weights)]\n",
    "    sum_multiplicated_list = sum(multiplicated_list)\n",
    "\n",
    "    # normalize known dimensions\n",
    "    cluster = 0\n",
    "    new_weights = np.zeros([CLUSTER_NUMBER])\n",
    "\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        r_i = ((c_list[cluster]*gmm_weights[cluster]) / sum_multiplicated_list)\n",
    "        new_weights = np.append(new_weights,r_i)\n",
    "        cluster += 1\n",
    "    # neue Gewichte\n",
    "    new_weights = new_weights[new_weights != 0]\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST\n",
    "# this is for testing the method with data for the unsafe dimensions (when x1,x3,x5 is known; y is x2,x4,x6,x7)\n",
    "# unsafe_dimensions: an numpy.array (y)\n",
    "# returns the density for all clusters as numpy.array\n",
    "def y_in_new_gmm(unsafe_dimensions,gmm_means,gmm_covariances, row, new_weights):\n",
    "    cluster = 0\n",
    "    new_normal_distribution_list = np.zeros([CLUSTER_NUMBER])\n",
    "    density_values = np.zeros([CLUSTER_NUMBER])\n",
    "    while cluster < CLUSTER_NUMBER:\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        subspace_means_unsafe_dimensions = np.delete(gmm_means[cluster], index_safe_dimensions,axis=0)\n",
    "\n",
    "        index_safe_dimensions = [index for index in range(len(row)) if MISSING_VALUE != row[index]]\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(np.diag(gmm_covariances[cluster]), index_safe_dimensions, axis=1)\n",
    "        subspace_covariances_unsafe_dimensions = np.delete(subspace_covariances_unsafe_dimensions, index_safe_dimensions, axis=0)\n",
    "\n",
    "        new_normal_distribution = multivariate_normal.pdf(unsafe_dimensions, mean=subspace_means_unsafe_dimensions, cov=subspace_covariances_unsafe_dimensions)\n",
    "        new_normal_distribution_list = np.append(new_normal_distribution_list, new_normal_distribution)\n",
    "\n",
    "        cluster += 1\n",
    "    \n",
    "    new_normal_distribution_list = new_normal_distribution_list[new_normal_distribution_list != 0]\n",
    "    r_and_new_value = [new_weights*new_normal_distribution_list for new_weights,new_normal_distribution_list in zip(new_weights,new_normal_distribution_list)]\n",
    "    sum_values = sum(r_and_new_value)\n",
    "    \n",
    "    i = 0\n",
    "    while i < CLUSTER_NUMBER:\n",
    "        normalized_new_normal_distribution = ((r_and_new_value[i]) / sum_values)\n",
    "        density_values = np.append(density_values,normalized_new_normal_distribution)\n",
    "        i += 1\n",
    "    density_values = density_values[density_values != 0]\n",
    "    print(density_values)\n",
    "    return density_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "# points: numpy.array with missing_values\n",
    "# returns a list of tupels which has the length of all incomplete data rows (when points has 25 rows with missing values the list of the tupels has the length of 25)\n",
    "# one tupel contains the new weights, new covariances and new means for the missing dimensions\n",
    "def gmm_distribution_missing_values(points):\n",
    "    means_covariances_weights_list = []\n",
    "    means_covariances_weights_list_gamma = []\n",
    "    new_weights_list = []\n",
    "    new_weights_gamma_list = []\n",
    "    # delete random values \n",
    "    \n",
    "    # delete a certain number of values\n",
    "    #points = delete_values_in_data(points, 100)\n",
    "\n",
    "    # delete values in one dimension\n",
    "    #points = delete_specific_values_in_one_dimension(points, 3, 20)\n",
    "\n",
    "    completes = split_data_in_completes(points)\n",
    "\n",
    "    gmm = GaussianMixture(covariance_type=\"diag\", n_components=CLUSTER_NUMBER, random_state = 3).fit(\n",
    "        completes[:1399])\n",
    "    gmm_means = np.array(gmm.means_)\n",
    "    gmm_covariances = np.array(gmm.covariances_)\n",
    "    gmm_weights = np.array(gmm.weights_)\n",
    "\n",
    "    #print(gmm_means)\n",
    "    #print(gmm_covariances)\n",
    "    #print(gmm_weights)\n",
    "    ### TEST\n",
    "    print(points[1400:])\n",
    "    pred_cluster = gmm.predict(points[1400:])\n",
    "    \n",
    "    points_incompletes = delete_random_values_in_data(points[1400:])\n",
    "\n",
    "    #probabilites = gmm.predict_proba([[-64,-56,-61,-66,-71,-82,-81]])\n",
    "    #print(\"Verteilungen mit vollständigem Wert durch GMM predicted (-64,-56,-61,-66,-71,-82,-81): \",probabilites)\n",
    "    #print(pred_cluster)\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_axes([0,0,1,1])\n",
    "    #ax.set_title('Prediction with complete values')\n",
    "    #ax.set_ylabel('Density')\n",
    "    #ax.set_xlabel('Cluster')\n",
    "    #langs = list(range(1,CLUSTER_NUMBER + 1))\n",
    "    #propabilities_list = probabilites.tolist()\n",
    "    #propabilities_rounded = [round(num,6) for num in propabilities_list[0]]\n",
    "    #propabilities\n",
    "    #pred_bar_chart = ax.bar(langs,propabilities_rounded)\n",
    "    #ax.bar_label(pred_bar_chart, label_type='edge')\n",
    "    #plt.show()\n",
    "\n",
    "    incompletes = split_data_in_incompletes(points)\n",
    "\n",
    "    for row in points_incompletes:\n",
    "        subspace_means_safe_dimensions = calculate_subspace_means_safe_dimensions(row, gmm_means)\n",
    "        subspace_covariances_safe_dimensions = calculate_subspace_covariances_safe_dimensions(row, gmm_covariances)\n",
    "        subspace_means_unsafe_dimensions = calculate_subspace_means_unsafe_dimensions(row, gmm_means)\n",
    "        subspace_covariances_unsafe_dimensions = calculate_subspace_covariances_unsafe_dimensions(row, gmm_covariances)\n",
    "        new_means = calculate_new_means(row, gmm_means)\n",
    "        new_covariances = calculate_new_covariances(row, gmm_covariances)\n",
    "        safe_dimensions = get_safe_dimensions(row)\n",
    "        c_list_gamma = calculate_c_with_gamma(row, gmm_means, gmm_covariances)\n",
    "        c_list = calculate_c(row, gmm_means, gmm_covariances)\n",
    "        new_weights_gamma = calculate_new_weights_gamma(c_list_gamma,gmm_weights)\n",
    "        new_weights = calculate_new_weights(c_list,gmm_weights)\n",
    "        #means_covariances_weights_one_row = new_means, new_covariances, new_weights\n",
    "        #means_covariances_weights_list.append(means_covariances_weights_one_row)\n",
    "        #means_covariances_weights_one_row_gamma = new_means, new_covariances, new_weights_gamma\n",
    "        #means_covariances_weights_list_gamma.append(means_covariances_weights_one_row_gamma)\n",
    "        new_weights_list.append(new_weights)\n",
    "        new_weights_gamma_list.append(new_weights_gamma)\n",
    "\n",
    "    ### TEST\n",
    "    #print(pred_cluster)\n",
    "    #new_normal_distribution_list = y_in_new_gmm([-64], gmm_means, gmm_covariances, row, new_weights)\n",
    "    #print(\"Geschätzte Werte: \" ,new_normal_distribution_list)\n",
    "    print(points_incompletes)\n",
    "    return new_weights_list, pred_cluster, new_weights_gamma_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cluster_new_gmm(new_weights, pred_cluster):\n",
    "    new_list = []\n",
    "    pred_cluster_list = []\n",
    "    i = 0\n",
    "    while i < 600:\n",
    "        max_index = new_weights[i].argmax(axis=0)\n",
    "        pred_cluster_list.append(max_index)\n",
    "        i += 1\n",
    "\n",
    "    new_list = [pred_cluster_list_i - pred_cluster_i for pred_cluster_list_i, pred_cluster_i in zip(pred_cluster_list, pred_cluster)]\n",
    "    print(len(new_list))\n",
    "    print(new_list.count(0))\n",
    "    #print(len(pred_cluster_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_cluster_new_gmm_gamma(new_weights_gamma, pred_cluster):\n",
    "    new_list = []\n",
    "    pred_cluster_list = []\n",
    "    i = 0\n",
    "    while i < 600:\n",
    "        max_index = new_weights_gamma[i].argmax(axis=0)\n",
    "        pred_cluster_list.append(max_index)\n",
    "        i += 1\n",
    "\n",
    "    new_list = [pred_cluster_list_i - pred_cluster_i for pred_cluster_list_i, pred_cluster_i in zip(pred_cluster_list, pred_cluster)]\n",
    "    print(\"Gamma:\",len(new_list))\n",
    "    print(new_list.count(0))\n",
    "    #print(len(pred_cluster_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-51 -55 -46 ... -63 -84 -79]\n",
      " [-52 -54 -53 ... -63 -86 -81]\n",
      " [-48 -57 -52 ... -62 -86 -81]\n",
      " ...\n",
      " [-62 -59 -46 ... -45 -87 -88]\n",
      " [-62 -58 -52 ... -41 -90 -85]\n",
      " [-59 -50 -45 ... -45 -88 -87]]\n",
      "[[    -51     -55     -46 ...     -63     -84 1000000]\n",
      " [1000000     -54     -53 ...     -63     -86     -81]\n",
      " [    -48     -57     -52 ... 1000000     -86     -81]\n",
      " ...\n",
      " [    -62     -59     -46 ...     -45 1000000     -88]\n",
      " [    -62     -58     -52 ...     -41     -90     -85]\n",
      " [    -59     -50     -45 ...     -45     -88 1000000]]\n",
      "600\n",
      "440\n",
      "Gamma: 600\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "new_weights, pred_cluster, new_weights_gamma = gmm_distribution_missing_values(points)\n",
    "pred_cluster_new_gmm(new_weights, pred_cluster)\n",
    "pred_cluster_new_gmm_gamma(new_weights_gamma, pred_cluster)\n",
    "#print(list_with_all_new_values[0])\n",
    "#incompletes = split_data_in_incompletes(points)\n",
    "#number_of_missing_values = np.count_nonzero(incompletes == MISSING_VALUE)\n",
    "#number_of_missing_values_str = str(number_of_missing_values)\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_axes([0,0,1,1])\n",
    "#ax.set_title('Prediction with ' + number_of_missing_values_str + ' missing value(s)')\n",
    "#ax.set_ylabel('Density')\n",
    "#ax.set_xlabel('Cluster')\n",
    "#langs = list(range(1,CLUSTER_NUMBER + 1))\n",
    "#propabilities = list_with_all_new_values[2][2][2]\n",
    "#propabilities_rounded = [round(num,6) for num in propabilities]\n",
    "#print(propabilities)\n",
    "#pred_bar_chart = ax.bar(langs,propabilities_rounded)\n",
    "#ax.bar_label(pred_bar_chart, label_type='edge')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list_with_all_new_values[1])\n",
    "#incompletes = split_data_in_incompletes(points)\n",
    "#number_of_missing_values = np.count_nonzero(incompletes == MISSING_VALUE)\n",
    "#number_of_missing_values_str = str(number_of_missing_values)\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_axes([0,0,1,1])\n",
    "#ax.set_title('Prediction with ' + number_of_missing_values_str + ' missing value(s) and gamma = 1')\n",
    "#ax.set_ylabel('Density')\n",
    "#ax.set_xlabel('Cluster')\n",
    "#langs = list(range(1,CLUSTER_NUMBER + 1))\n",
    "#propabilities = list_with_all_new_values[1][0][2]\n",
    "#propabilities_rounded = [round(num,6) for num in propabilities]\n",
    "#print(propabilities)\n",
    "#pred_bar_chart = ax.bar(langs,propabilities_rounded)\n",
    "#ax.bar_label(pred_bar_chart, label_type='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completes = split_data_in_completes(points)\n",
    "#completes\n",
    "#new_gmm = GaussianMixture(n_components = 10,covariance_type = 'diag',weights_init=list_with_all_new_values[0][2],means_init=[0][0]).fit(completes)\n",
    "#new_gmm.predict_proba([[-64,-61]])\n",
    "#new_gmm_means = np.array(new_gmm.means_)\n",
    "#new_gmm_covariances = np.array(new_gmm.covariances_)\n",
    "#new_gmm_weights = np.array(new_gmm.weights_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e6e376889b46e5d2afa5f6d19b0811f4e7fea2a291bc45d33c4bc190b0b6db"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
